{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN AUTOENCODER ver1.2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMokIgqqRUyi1UcEsnA0qhl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSID-DGU/2021-1-OSSP1-Debugger-4/blob/autoencoder/CNN_AUTOENCODER_ver1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_xokBzTiQtn"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSiZk-UaiSKY"
      },
      "source": [
        "# 라이브러리 설정\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import gc\n",
        "import glob\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape\n",
        "\n",
        "# 랜덤 시드 고정\n",
        "SEED=2021\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSZ2CyoriW5o"
      },
      "source": [
        "#CelebA Unzip(사용자별 각자 설정 필요)\n",
        "import zipfile\n",
        "zipfile.ZipFile('./drive/MyDrive/img_align_celeba.zip').extractall('./celeba')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6KlJNhrieLt"
      },
      "source": [
        "#CelebA 이미지 데이터 불러오기\n",
        "imgs = glob.glob('./celeba/img_align_celeba/*.jpg') #경로저장\n",
        "\n",
        "#데이터를 불러오는 과정\n",
        "train_y = []\n",
        "for _ in range(0,100000):\n",
        "  if _%20000 == 0:\n",
        "    print(\"{} / 100000\".format(_))\n",
        "  img = cv2.imread(imgs[_])\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(64,64),interpolation = cv2.INTER_AREA)\n",
        "  train_y.append(img.astype(\"float32\")/255.0)\n",
        "  del img\n",
        "\n",
        "Y = np.array(train_y)\n",
        "del train_y\n",
        "train_y=[]\n",
        "gc.collect()\n",
        "\n",
        "#데이터를 불러오는 과정2 \n",
        "for _ in range(100000,200000):\n",
        "  if _%20000 == 0:\n",
        "    print(\"{} / 100000\".format(_))\n",
        "  img = cv2.imread(imgs[_])\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(64,64),interpolation = cv2.INTER_AREA)\n",
        "  train_y.append(img.astype(\"float32\")/255.0)\n",
        "  del img\n",
        "\n",
        "#최종 데이터가 저장된 Y\n",
        "Y = np.vstack((Y,train_y))\n",
        "\n",
        "del train_y\n",
        "gc.collect()\n",
        "\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t4o_2IijBj9"
      },
      "source": [
        "#테스트 데이터 저장과정\n",
        "test_Y = []\n",
        "for _ in range(200000,202599):\n",
        "  img = cv2.imread(imgs[_])\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(64,64),interpolation = cv2.INTER_AREA)\n",
        "  test_Y.append(img.astype(\"float32\")/255.0)\n",
        "  \n",
        "test_Y = np.array(test_Y)\n",
        "print(test_Y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6mZuFVZjMGR"
      },
      "source": [
        "#실제 인물 데이터 불러오기\n",
        "'''minsu = glob.glob('./drive/MyDrive/videoimage3/*.png')\n",
        "test_minsu = []\n",
        "for _ in range(0,1000):\n",
        "  img = cv2.imread(minsu[_])\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img,(64,64),interpolation = cv2.INTER_AREA)\n",
        "  test_minsu.append(img.astype(\"float32\")/255.0)\n",
        "  \n",
        "test_minsu = np.array(test_minsu)\n",
        "\n",
        "print(test_minsu.shape)'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmqhmeMJjuFh"
      },
      "source": [
        "# 오토인코더 모델 정의\n",
        "def Autoencoder():\n",
        "  #model = Sequnetial()\n",
        "\n",
        "  X = tf.keras.layers.Input(shape=[64,64,3])\n",
        "\n",
        "  #Encoder\n",
        "  H = tf.keras.layers.Conv2D(32,(4,4),(2,2),activation='relu',padding='same')(X)\n",
        "  H = tf.keras.layers.Conv2D(32*2,(4,4), (2,2),activation='relu',padding='same')(H)\n",
        "  H = tf.keras.layers.Conv2D(32*4, (4,4),(2,2),activation='relu',padding='same')(H)\n",
        "  H = tf.keras.layers.Conv2D(32*8, (4,4),(2,2),activation='relu',padding='same')(H)\n",
        "\n",
        "\n",
        "  pool_tmp = H.shape.as_list()\n",
        "  pool_tmp=pool_tmp[1:]\n",
        "  \n",
        "\n",
        "  #Fully-Connected\n",
        "  H = tf.keras.layers.Flatten()(H)\n",
        "  flatten_tmp=H.shape.as_list()\n",
        "  flatten_tmp=flatten_tmp[1]\n",
        "  H = tf.keras.layers.Dense(100,activation='relu')(H)\n",
        "  H = tf.keras.layers.Dense(flatten_tmp,activation='relu')(H)\n",
        "  H = Reshape(pool_tmp)(H)\n",
        "\n",
        "\n",
        "  #Decoder\n",
        "  H = tf.keras.layers.Conv2DTranspose(32*4,(2,2),strides=(2,2),padding='same',activation='relu')(H)\n",
        "  H = tf.keras.layers.Conv2DTranspose(32*2,(2,2),strides=(2,2),padding='same',activation='relu')(H)\n",
        "  H = tf.keras.layers.Conv2DTranspose(32,(2,2),strides=(2,2),padding='same',activation='relu')(H)\n",
        "  H = tf.keras.layers.Conv2DTranspose(3,(2,2),strides=(2,2),padding='same',activation='relu')(H)\n",
        "\n",
        "  model = tf.keras.models.Model(X,H)\n",
        "  model.compile(optimizer='adam',loss='mean_squared_error', metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "ae_model = Autoencoder()\n",
        "ae_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSpo33iZjuoJ"
      },
      "source": [
        "#모델 체크포인트 설정\n",
        "checkpoint_path = 'checkpoint.ckpt'\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                save_weights_only = True,\n",
        "                                                save_best_only = True,\n",
        "                                                moitor='val_accuracy',\n",
        "                                                verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8F6CkXsjyDQ"
      },
      "source": [
        "# 오토인코더 모델 학습\n",
        "history = ae_model.fit(Y,\n",
        "                       Y,\n",
        "                       batch_size=200,\n",
        "                       epochs=20,\n",
        "                       verbose=1,\n",
        "                       callbacks=[checkpoint],\n",
        "                       \n",
        "                       validation_split=0.2)\n",
        "                       #validation_data=(val_data, val_data))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqvIYLn6j3Rk"
      },
      "source": [
        "#테스트 데이터 Prediction\n",
        "ae_images = ae_model.predict(test_Y)\n",
        "ae_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vDVTOe0j_IW"
      },
      "source": [
        "#이미지 출력\n",
        "num = 10 \n",
        "plt.figure(figsize=(20,8))\n",
        "for i in range(10):\n",
        "    # 원본 이미지\n",
        "    ax = plt.subplot(2, num, i+1)\n",
        "    plt.imshow(test_Y[i*50].reshape((64,64,3)))\n",
        "    plt.title(\"Original %s\" % str(i))\n",
        "    plt.axis('off')\n",
        "    \n",
        "    # 복원 이미지\n",
        "    ax = plt.subplot(2, num, i+num+1)\n",
        "    plt.imshow(ae_images[i*50].reshape((64,64,3)))\n",
        "    plt.title(\"Auto-encoded %s\" % str(i))\n",
        "    plt.axis('off')\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}