{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOB86qGhjxkp5k0Xoc5AlyD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSID-DGU/2021-1-OSSP1-Debugger-4/blob/face-recognization/final_synthesis_ver4.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNDjRmRe78_V"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"image_merge_version1.1.ipynb\n",
        "Automatically generated by Colaboratory.\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1r_H8Q9qY8__p7BATDe8befrsNgU6ImPk\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('./gdrive')\n",
        "\n",
        "from imutils import face_utils\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import imutils\n",
        "import dlib\n",
        "import cv2\n",
        "import math\n",
        "\n",
        "\n",
        "# 얼굴 Detection 및 Landmark 생성\n",
        "def faceDetection(img, detector, predictor):\n",
        "  #h, w, ch = img.shape\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  rects = detector(gray,1)\n",
        "  roi = rects[0]\n",
        "  shape = predictor(gray, roi)\n",
        "  shape = face_utils.shape_to_np(shape)\n",
        "  return shape\n",
        "\n",
        "\n",
        "#마스크부분 추출\n",
        "def extractMask(landmark, img):\n",
        "  h, w, ch = img.shape\n",
        "  # extract jawline\n",
        "  jawline = landmark[0:17]\n",
        "  temp_face = landmark[1:16]\n",
        "  lefteye = landmark[36:42]\n",
        "  righteye = landmark[42:48]\n",
        "\n",
        "  nose = landmark[27][1]\n",
        "\n",
        "  top = nose\n",
        "  bottom = max(jawline[:,1])\n",
        "  side1 = min(jawline[:,0])\n",
        "  side2 = max(jawline[:,0])\n",
        "  side = side2-side1\n",
        "\n",
        "  lefteyeline = max(lefteye[:,1])\n",
        "  righteyeline = max(righteye[:,1])\n",
        "\n",
        "  temp_face = np.insert(temp_face,0,[landmark[0][0],landmark[40][1]]).reshape(-1,2)\n",
        "  temp_face = np.append(temp_face,[landmark[16][0],landmark[47][1]]).reshape(-1,2)\n",
        "  # extend contour for masking\n",
        "  jawline = np.append(jawline, [landmark[47][0],landmark[47][1]]).reshape(-1,2)\n",
        "  temp_face = np.append(temp_face, [landmark[47][0],landmark[47][1]]).reshape(-1,2)\n",
        "  jawline = np.append(jawline, [landmark[27][0],landmark[27][1]]).reshape(-1,2)\n",
        "  temp_face = np.append(temp_face, [landmark[27][0],landmark[27][1]]).reshape(-1,2)\n",
        "  jawline = np.append(jawline, [ w-1, nose]).reshape(-1,2)\n",
        "  temp_face = np.append(temp_face, [w-1,nose]).reshape(-1,2)\n",
        "  jawline = np.append(jawline, [ w-1, h-1 ]).reshape(-1, 2)\n",
        "  temp_face = np.append(temp_face,[w-1,h-1]).reshape(-1,2)\n",
        "  jawline = np.append(jawline, [ 0, h-1 ]).reshape(-1, 2)\n",
        "  temp_face = np.append(temp_face,[0,h-1]).reshape(-1,2)\n",
        "  jawline = np.append(jawline, [0, nose]).reshape(-1,2)\n",
        "  temp_face = np.append(temp_face,[0,nose]).reshape(-1,2)\n",
        "  jawline = np.append(jawline, [landmark[27][0],landmark[27][1]]).reshape(-1,2)\n",
        "  temp_face = np.append(temp_face,[landmark[27][0],landmark[27][1]]).reshape(-1,2)\n",
        "  jawline = np.append(jawline, [landmark[40][0],landmark[40][1]]).reshape(-1,2)\n",
        "  temp_face = np.append(temp_face, [landmark[40][0],landmark[40][1]]).reshape(-1,2)\n",
        "  jawline = np.append(jawline, [landmark[0][0], landmark[0][1] ]).reshape(-1, 2)\n",
        "  temp_face = np.append(temp_face, [landmark[0][0], landmark[40][1]]).reshape(-1,2)\n",
        "  contours = [jawline]\n",
        "  temp_contours = [temp_face]\n",
        "\n",
        "  # generate mask\n",
        "  mask = np.ones((h,w,1), np.uint8) * 255 # times 255 to make mask 'showable'\n",
        "  \n",
        "  #cv2.drawContours(mask, contours, -1, 0, -1) # remove below jawline\n",
        "  cv2.drawContours(mask, temp_contours, -1,0,-1)\n",
        "  \n",
        "\n",
        "  # apply to image\n",
        "  result = cv2.bitwise_and(img, img, mask = mask)\n",
        "  '''\n",
        "  for i in range(len(temp_face)-1):\n",
        "    cv2.line(result,(temp_face[i],temp_face[i+1]),(177,206,251),1)\n",
        "  '''\n",
        "  b,g,r = img[landmark[27][1],landmark[27][0]]\n",
        "  result = result[nose:bottom, side1:side2] # crop ROI\n",
        "  return result\n",
        "\n",
        "\n",
        "\n",
        "def coloring(img, img2, landmark_1, landmark_2):\n",
        "  x1_img1 = int(landmark_1[0][0] + landmark_1[36][0] / 2)\n",
        "  y1_img1 = landmark_1[36][1]\n",
        "  x1_img2 = int(landmark_2[0][0] + landmark_2[36][0] / 2)\n",
        "  y1_img2 = landmark_2[36][1]\n",
        "\n",
        "  x2_img1 = int((landmark_1[39][0] + landmark_1[27][0]) / 2)\n",
        "  y2_img1 = landmark_1[27][1]\n",
        "  x2_img2 = int((landmark_2[39][0] + landmark_2[27][0]) / 2)\n",
        "  y2_img2 = landmark_2[27][1]\n",
        "\n",
        "  x3_img1 = int((landmark_1[27][0] + landmark_1[42][0]) / 2)\n",
        "  y3_img1 = landmark_1[27][1]\n",
        "  x3_img2 = int((landmark_2[27][0] + landmark_2[42][0]) / 2)\n",
        "  y3_img2 = landmark_2[27][1]\n",
        "\n",
        "  x4_img1 = int((landmark_1[45][0] + landmark_1[16][0]) / 2)\n",
        "  y4_img1 = landmark_1[45][1]\n",
        "  x4_img2 = int((landmark_2[45][0] + landmark_2[16][0]) / 2)\n",
        "  y4_img2 = landmark_2[45][1]\n",
        "\n",
        "  b_1,g_1,r_1 = img[x1_img1][y1_img1]\n",
        "  b_2,g_2,r_2 = img[x2_img1][y2_img1]\n",
        "  b_3,g_3,r_3 = img[x3_img1][y3_img1]\n",
        "  b_4,g_4,r_4 = img[x4_img1][y4_img1]\n",
        "  b = (b_1+b_2+b_3+b_4)/4\n",
        "  g = (g_1+g_2+g_3+g_4)/4\n",
        "  r = (r_1+r_2+r_3+r_4)/4\n",
        "  #print(b,g,r)\n",
        "\n",
        "  b2_1,g2_1,r2_1 = img2[x1_img2][y1_img2]\n",
        "  b2_2,g2_2,r2_2 = img2[x2_img2][y2_img2]\n",
        "  b2_3,g2_3,r2_3 = img2[x3_img2][y3_img2]\n",
        "  b2_4,g2_4,r2_4 = img2[x4_img2][y4_img2]\n",
        "  b2 = (b2_1+b2_2+b2_3+b2_4)/4\n",
        "  g2 = (g2_1+g2_2+g2_3+g2_4)/4\n",
        "  r2 = (r2_1+r2_2+r2_3+r2_4)/4\n",
        "  #print(b2,g2,r2)\n",
        "\n",
        "  blue = int(b-b2)\n",
        "  green = int(g-g2)\n",
        "  red = int(r-r2)\n",
        "\n",
        "  val = min(abs(red), abs(green), abs(blue))\n",
        "  if(val == -red or val == -blue or val == -green):\n",
        "    val = val * -1\n",
        "  \n",
        "  if(val>0):    \n",
        "    array = np.full(img2.shape, (val, val, val), dtype = np.uint8)\n",
        "    img2 = cv2.add(img2, array)\n",
        "  else:\n",
        "    array = np.full(img2.shape, (-val, -val, -val), dtype = np.uint8)\n",
        "    img2 = cv2.subtract(img2, array)\n",
        "  return img2\n",
        "\n",
        "def rotate(img,p1,p2,p3,p4):\n",
        "  w,h = img.shape[:2]\n",
        "\n",
        "  tan1 = math.atan2(p1[1]-p2[1],p1[0]-p2[0])\n",
        "  res1 = tan1 * 180 / math.pi\n",
        "\n",
        "  tan2 = math.atan2(p3[1]-p4[1],p3[0]-p4[0])\n",
        "  res2 = tan2 * 180 / math.pi\n",
        "\n",
        "  if(res1<0): #오른쪽으로 돌아간 사진\n",
        "    handle = \"right\"\n",
        "  else:\n",
        "    handle = \"left\"\n",
        "  #cp = (img.shape[1]/2, img.shape[0]/2)\n",
        "  if(handle == \"right\"):\n",
        "    rot = cv2.getRotationMatrix2D((0,0), res2-res1,1)\n",
        "  else:\n",
        "    rot = cv2.getRotationMatrix2D((w,0), res2-res1,1)\n",
        "  img = cv2.warpAffine(img, rot, (0, 0)) \n",
        "  return img, handle\n",
        "\n",
        "    \n",
        "# 두 이미지 합하기, img_mask : 마스크부분만 자른 이미지, img : 마스크낀 이미지 landmark_1 : 마스크를 낀 사진의 landmark, landmark2 : 마스크를 안낀 사진의 landmark\n",
        "def func(hpos, vpos, img_mask, img, landmark_1, landmark_2, handle):\n",
        "  x1 = landmark_1[0][0] - landmark_1[16][0]\n",
        "  y1 = landmark_1[0][1] - landmark_1[16][1]\n",
        "  c = math.sqrt((x1**2)+(y1**2))\n",
        "\n",
        "  x2 = landmark_2[0][0] - landmark_2[16][0]\n",
        "  y2 = landmark_2[0][1] - landmark_2[16][1]\n",
        "  c2 = math.sqrt((x2**2)+(y2**2))\n",
        "  size_w = c/c2\n",
        "\n",
        "  x3 = landmark_1[27][0] - landmark_1[8][0]\n",
        "  y3 = landmark_1[27][1] - landmark_1[8][1]\n",
        "  c3 = math.sqrt((x3**2)+(y3**2))\n",
        "\n",
        "  x4 = landmark_2[27][0] - landmark_2[8][0]\n",
        "  y4 = landmark_2[27][1] - landmark_2[8][1]\n",
        "  c4 = math.sqrt((x4**2)+(y4**2))\n",
        "  size_h = c3/c4\n",
        "  \n",
        "  src = img_mask\n",
        "  #cv2_imshow(src)\n",
        "  src = cv2.resize(src, dsize=(0,0), fx =size_w, fy= size_h, interpolation = cv2.INTER_LINEAR)\n",
        "  rows, cols, channels = src.shape\n",
        "  if handle==\"right\":\n",
        "    roi = img[hpos:rows+hpos,vpos:cols+vpos]\n",
        "  else:\n",
        "    roi = img[hpos:rows+hpos,vpos-cols:vpos]\n",
        "  \n",
        "  background = np.ones((rows,cols,3), np.uint8)*0\n",
        "  gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
        "  ret, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)\n",
        "  mask_inv = cv2.bitwise_not(mask)\n",
        "\n",
        "  src_s = cv2.resize(src, dsize=(0,0), fx = 0.985, fy = 0.985, interpolation = cv2.INTER_LINEAR)\n",
        "  row2, col2, ch2 = src_s.shape\n",
        "  y = (int)((rows - row2)/2)\n",
        "  x = (int)((cols -col2)/2)\n",
        "  background[y:y+row2, x:x+col2] = src_s\n",
        "\n",
        "  gray_s = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)\n",
        "  r, mask_s = cv2.threshold(gray_s, 0, 255, cv2.THRESH_BINARY)\n",
        "  mask_inv = cv2.bitwise_not(mask_s)\n",
        "\n",
        "  \n",
        "  img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
        "  src_fg = cv2.bitwise_and(src, src, mask=mask_s)\n",
        "  tmp = cv2.addWeighted(img_bg, 1, src_fg, 1,0)\n",
        "\n",
        "  tmp=cv2.medianBlur(tmp,9)\n",
        "  if handle == \"right\":\n",
        "    img[hpos:rows+hpos, vpos:cols+vpos] = tmp\n",
        "  else:\n",
        "    img[hpos:rows+hpos, vpos-cols:vpos] = tmp\n",
        "  return img, tmp\n",
        "\n",
        "\n",
        "def output(img):\n",
        "    image = img\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    rects = detector(gray, 1)\n",
        "    for i in rects:\n",
        "        x1 = i.left()\n",
        "        x2 = i.right()\n",
        "        y1 = i.top()\n",
        "        y2 = i.bottom()\n",
        "    tmp = image[y1:y2, x1:x2]\n",
        "    tmp = cv2.resize(tmp, dsize=(800, 800), interpolation=cv2.INTER_AREA)\n",
        "    cv2_imshow(tmp)\n",
        "    list_xy = [x1,x2,y1,y2]\n",
        "    return tmp,list_xy\n",
        "\n",
        "\n",
        "#2차 합성\n",
        "def replace(img, eimg,list_ab):\n",
        "  h1, w1, ch1 = eimg.shape\n",
        "  h = (list_ab[3]-list_ab[2])/h1\n",
        "  w = (list_ab[1]-list_ab[0])/w1\n",
        "  eimg = cv2.resize(eimg, dsize=(0,0),fx=w,fy=h, interpolation = cv2.INTER_LINEAR)\n",
        "  cv2_imshow(eimg)\n",
        "  img[list_ab[2]:list_ab[3], list_ab[0]:list_ab[1]] = eimg\n",
        "  return img\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "pred = \"./gdrive/MyDrive/opencv/shape_predictor_68_face_landmarks.dat\"\n",
        "predictor = dlib.shape_predictor(pred)\n",
        "\n",
        "img_path = \"./gdrive/MyDrive/opencv/face2.jpg\"  #마스크 낀 사진\n",
        "image = cv2.imread(img_path)\n",
        "#cv2_imshow(image)\n",
        "\n",
        "img_path2 = \"./gdrive/MyDrive/opencv/nomask.png\"  #마스크 안낀 사진\n",
        "image2 = cv2.imread(img_path2)\n",
        "\n",
        "landmark1 = np.empty((68,2),int)\n",
        "landmark2 = np.empty((68,2),int)\n",
        "\n",
        "landmark1 = faceDetection(image, detector, predictor)\n",
        "landmark2 = faceDetection(image2, detector, predictor)\n",
        "\n",
        "image2 = coloring(image,image2,landmark1,landmark2)\n",
        "show_mask = extractMask(landmark2, image2)\n",
        "show_mask,r = rotate(show_mask, landmark1[36],landmark1[45],landmark2[36], landmark2[45])\n",
        "\n",
        "if(r == \"right\"):\n",
        "  merged_img, show_mask = func(landmark1[40][1],landmark1[0][0], show_mask, image, landmark1, landmark2, r)\n",
        "else:\n",
        "  merged_img, show_mask = func(landmark1[40][1],landmark1[16][0], show_mask, image, landmark1, landmark2, r)\n",
        "\n",
        "face_img, xy_list = output(merged_img)\n",
        "cv2.imwrite(\"./gdrive/MyDrive/opencv/faceimg.png\",face_img)\n",
        "\n",
        "img_encoded = cv2.imread(\"/content/gdrive/MyDrive/opencv/encode.jpg\")\n",
        "merged_img = replace(merged_img, img_encoded, xy_list)\n",
        "cv2.imwrite(\"./gdrive/MyDrive/opencv/result.png\",merged_img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}