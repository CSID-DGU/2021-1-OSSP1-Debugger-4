{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "Training_K_Face_model_with_Server.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSID-DGU/2021-1-OSSP1-Debugger-4/blob/autoencoder/Training_K_Face_model_with_Server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJH9BM_gXO6j"
      },
      "source": [
        "# Set the Library"
      ],
      "id": "iJH9BM_gXO6j"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0af9b8f4"
      },
      "source": [
        "# 라이브러리 설정\n",
        "import numpy as np\n",
        "import cupy\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import gc\n",
        "import glob\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from keras.models import load_model\n",
        "import keras\n",
        "\n",
        "# 랜덤 시드 고정\n",
        "SEED=2021\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "id": "0af9b8f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rp6vLlNXXYC"
      },
      "source": [
        " # Load the NPZ file containing K-FACE Images (For Pre-trained Model)"
      ],
      "id": "3Rp6vLlNXXYC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "671c6933",
        "outputId": "9ee3fecb-173e-4ede-eec9-e940ce73cce5"
      },
      "source": [
        "load_y=np.load('../Upscaling/Dataset_output/NON-WEAR_dataset.npz') \n",
        "Y_1 =load_y['arr_0']\n",
        "load_y.close()\n",
        "\n",
        "\n",
        "#Test Data\n",
        "Y_test = Y_1[-1000:] \n",
        "Y_1 = Y_1[:-1000]\n",
        "\n",
        "\n",
        "del load_y\n",
        "print(Y_1.shape)\n",
        "gc.collect()"
      ],
      "id": "671c6933",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21400, 800, 800, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pXORPW1XcnL"
      },
      "source": [
        "#Using Multi GPU"
      ],
      "id": "-pXORPW1XcnL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1e6756a",
        "outputId": "e65c3b11-ca42-4d46-81c9-c326b55d0009"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\",\"/gpu:1\",\"/gpu:2\",\"/gpu:3\",\"/gpu:4\",\"/gpu:5\",\"/gpu:6\",\"/gpu:7\"])"
      ],
      "id": "f1e6756a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 Physical GPUs, 8 Logical GPUs\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyK_xEKLXgwi"
      },
      "source": [
        "# Set the Model_checkpoint & Train the Model"
      ],
      "id": "zyK_xEKLXgwi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97809d91"
      },
      "source": [
        "#모델 체크포인트 설정\n",
        "checkpoint_path = './check/checkpoint.ckpt'\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                save_weights_only = True,\n",
        "                                                save_best_only = True,\n",
        "                                                monitor='val_acc',\n",
        "                                                verbose=1)"
      ],
      "id": "97809d91",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4c923810"
      },
      "source": [
        "with strategy.scope():\n",
        "    history = ae_model.fit(Y_1,\n",
        "                       Y_1,\n",
        "                       batch_size=128, #한번에 학습할 데이터 Batch_size\n",
        "                       epochs=300,      #에포크 설정\n",
        "                       verbose=1,      #학습과정 시각화     \n",
        "                       callbacks=[checkpoint],  #모델 체크포인트 저장\n",
        "                       validation_split=0.2)         \n",
        "\n",
        "#Save the model\n",
        "ae_model.save('./check/model2.h5')"
      ],
      "id": "4c923810",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMY7M-JzYITe"
      },
      "source": [
        "Test the Model (Pre-trained Model)"
      ],
      "id": "VMY7M-JzYITe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "60f5c26d"
      },
      "source": [
        "ae_images = ae_model.predict(Y_test)  #Pre-trained Model 평가용\n",
        "ae_images.shape"
      ],
      "id": "60f5c26d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sKQv8SuYPpf"
      },
      "source": [
        "Print the Predict Result (Pre-trained Model)"
      ],
      "id": "2sKQv8SuYPpf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00759714"
      },
      "source": [
        "#이미지 출력\n",
        "num = 10 \n",
        "plt.figure(figsize=(20,8))\n",
        "for i in range(10):\n",
        "    # 원본 이미지\n",
        "    ax = plt.subplot(2, num, i+1)\n",
        "    plt.imshow(Y_test[i*10])\n",
        "    plt.title(\"Original %s\" % str(i))\n",
        "    plt.axis('off')\n",
        "    \n",
        "    # 복원 이미지\n",
        "    ax = plt.subplot(2, num, i+num+1)\n",
        "    plt.imshow(ae_images[i*10])\n",
        "    plt.title(\"Auto-encoded %s\" % str(i))\n",
        "    plt.axis('off')\n",
        "    \n",
        "plt.show()"
      ],
      "id": "00759714",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caefe1df"
      },
      "source": [
        "# ================ Transfer Learning (For User) ================"
      ],
      "id": "caefe1df"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGtPN2CPYaSb"
      },
      "source": [
        "#Load the Pre-trained Model"
      ],
      "id": "wGtPN2CPYaSb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ7eKc3cXKtz"
      },
      "source": [
        "with strategy.scope():\n",
        "    ae_model = load_model('./check/models/model2.h5')"
      ],
      "id": "QZ7eKc3cXKtz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvy7jaA6ZkT1"
      },
      "source": [
        "#Load the Dataset for Transfer Learning (Video Frame set + Input Image)"
      ],
      "id": "tvy7jaA6ZkT1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7np332xqZ3AF"
      },
      "source": [
        "#팀장 데이터 불러오기 (Pre-Trained Model에 추가학습용) -> 동영상 프레임 추출 사진\n",
        "minsu = glob.glob('./TransferLearningImages/videoimage3/*.png')\n",
        "test_minsu = []\n",
        "for _ in range(0,100):\n",
        "  img = cv2.imread(minsu[_])\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  test_minsu.append(img.astype(\"float32\")/255.0)\n",
        "  \n",
        "\n",
        "#합성사진 추가\n",
        "testpath = '800x800.png'\n",
        "img = cv2.imread(testpath)\n",
        "img=(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "test_minsu.append(img.astype(\"float32\")/255.0)\n",
        "test_minsu.append(img.astype(\"float32\")/255.0)\n",
        "test_minsu.append(img.astype(\"float32\")/255.0)\n",
        "test_minsu.append(img.astype(\"float32\")/255.0)\n",
        "test_minsu.append(img.astype(\"float32\")/255.0)\n",
        "\n",
        "val_minsu=[]\n",
        "val_minsu.append(test_minsu[-1])\n",
        "test_minsu = np.array(test_minsu)\n",
        "val_minsu = np.array(val_minsu)\n",
        "np.random.shuffle(test_minsu)\n",
        "\n",
        "print(test_minsu.shape)"
      ],
      "id": "7np332xqZ3AF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f08d3ff1"
      },
      "source": [
        "# Training the Model"
      ],
      "id": "f08d3ff1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15269df5"
      },
      "source": [
        "ae_model.compile(optimizer=keras.optimizers.Adam(1e-4),loss='mean_squared_error', metrics=['val_acc']) \n",
        "ae_model.summary()"
      ],
      "id": "15269df5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ac1c9f"
      },
      "source": [
        "#모델 체크포인트 설정\n",
        "checkpoint_path = 'checkpoint.ckpt'\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                save_weights_only = True,\n",
        "                                                save_best_only = True,\n",
        "                                                monitor='val_acc',\n",
        "                                                verbose=1)"
      ],
      "id": "80ac1c9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "90dabe9e"
      },
      "source": [
        "history = ae_model.fit(test_minsu,\n",
        "                       test_minsu,\n",
        "                       batch_size=10, \n",
        "                       epochs=30,    \n",
        "                       verbose=1,\n",
        "                       validation_data=(val_minsu, val_minsu),                                                        \n",
        "                       callbacks=[checkpoint])  #모델 체크포인트 저장\n",
        "                      \n",
        "#Save the MoDEL\n",
        "ae_model.save('./check/transfer.h5')"
      ],
      "id": "90dabe9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4ljb5hIa3SZ"
      },
      "source": [
        "# Generate & Show the Output"
      ],
      "id": "X4ljb5hIa3SZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b651b33"
      },
      "source": [
        "trans_imgs = ae_model.predict(val_minsu)"
      ],
      "id": "7b651b33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e6e93af"
      },
      "source": [
        "plt.imshow(trans_img[0])\n",
        "plt.show()"
      ],
      "id": "0e6e93af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aYCSPrMbNDR"
      },
      "source": [
        "# Save the Output Images"
      ],
      "id": "7aYCSPrMbNDR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR7P0QwcbRCX"
      },
      "source": [
        "cv2.imwrite('output.jpg', cv2.cvtColor(trans_img[0]*255, cv2.COLOR_BGR2RGB))"
      ],
      "id": "dR7P0QwcbRCX",
      "execution_count": null,
      "outputs": []
    }
  ]
}