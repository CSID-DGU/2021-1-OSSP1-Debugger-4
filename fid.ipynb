{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fid.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXynp78fxpIk8w5X+bvJrS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSID-DGU/2021-1-OSSP1-Debugger-4/blob/Fid-score/fid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxrePmQkC6Xr"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "''' Calculates the Frechet Inception Distance (FID) to evalulate GANs.\n",
        "The FID metric calculates the distance between two distributions of images.\n",
        "Typically, we have summary statistics (mean & covariance matrix) of one\n",
        "of these distributions, while the 2nd distribution is given by a GAN.\n",
        "When run as a stand-alone program, it compares the distribution of\n",
        "images that are stored as PNG/JPEG at a specified location with a\n",
        "distribution given by summary statistics (in pickle format).\n",
        "The FID is calculated by assuming that X_1 and X_2 are the activations of\n",
        "the pool_3 layer of the inception net for generated samples and real world\n",
        "samples respectivly.\n",
        "See --help to see further details.\n",
        "'''\n",
        "\n",
        "from __future__ import absolute_import, division, print_function\n",
        "import numpy as np\n",
        "import os\n",
        "import gzip, pickle\n",
        "import tensorflow as tf\n",
        "from imageio import imread\n",
        "from scipy import linalg\n",
        "import pathlib\n",
        "import urllib\n",
        "import warnings\n",
        "\n",
        "class InvalidFIDException(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def create_inception_graph(pth):\n",
        "    \"\"\"Creates a graph from saved GraphDef file.\"\"\"\n",
        "    # Creates graph from saved graph_def.pb.\n",
        "    with tf.io.gfile.GFile( pth, 'rb') as f:\n",
        "        graph_def = tf.compat.v1.GraphDef()\n",
        "        graph_def.ParseFromString( f.read())\n",
        "        _ = tf.import_graph_def( graph_def, name='FID_Inception_Net')\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# code for handling inception net derived from\n",
        "#   https://github.com/openai/improved-gan/blob/master/inception_score/model.py\n",
        "def _get_inception_layer(sess):\n",
        "    \"\"\"Prepares inception net for batched usage and returns pool_3 layer. \"\"\"\n",
        "    layername = 'FID_Inception_Net/pool_3:0'\n",
        "    pool3 = sess.graph.get_tensor_by_name(layername)\n",
        "    ops = pool3.graph.get_operations()\n",
        "    for op_idx, op in enumerate(ops):\n",
        "        for o in op.outputs:\n",
        "            shape = o.get_shape()\n",
        "            if shape._dims is not None:\n",
        "              #shape = [s.value for s in shape] TF 1.x\n",
        "              shape = [s for s in shape] #TF 2.x\n",
        "              new_shape = []\n",
        "              for j, s in enumerate(shape):\n",
        "                if s == 1 and j == 0:\n",
        "                  new_shape.append(None)\n",
        "                else:\n",
        "                  new_shape.append(s)\n",
        "              o.__dict__['_shape_val'] = tf.TensorShape(new_shape)\n",
        "    return pool3\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def get_activations(images, sess, batch_size=50, verbose=False):\n",
        "    \"\"\"Calculates the activations of the pool_3 layer for all images.\n",
        "    Params:\n",
        "    -- images      : Numpy array of dimension (n_images, hi, wi, 3). The values\n",
        "                     must lie between 0 and 256.\n",
        "    -- sess        : current session\n",
        "    -- batch_size  : the images numpy array is split into batches with batch size\n",
        "                     batch_size. A reasonable batch size depends on the disposable hardware.\n",
        "    -- verbose    : If set to True and parameter out_step is given, the number of calculated\n",
        "                     batches is reported.\n",
        "    Returns:\n",
        "    -- A numpy array of dimension (num images, 2048) that contains the\n",
        "       activations of the given tensor when feeding inception with the query tensor.\n",
        "    \"\"\"\n",
        "    inception_layer = _get_inception_layer(sess)\n",
        "    n_images = images.shape[0]\n",
        "    if batch_size > n_images:\n",
        "        print(\"warning: batch size is bigger than the data size. setting batch size to data size\")\n",
        "        batch_size = n_images\n",
        "    n_batches = n_images//batch_size # drops the last batch if < batch_size\n",
        "    pred_arr = np.empty((n_batches * batch_size,2048))\n",
        "    for i in range(n_batches):\n",
        "        if verbose:\n",
        "            print(\"\\rPropagating batch %d/%d\" % (i+1, n_batches), end=\"\", flush=True)\n",
        "        start = i*batch_size\n",
        "        \n",
        "        if start+batch_size < n_images:\n",
        "            end = start+batch_size\n",
        "        else:\n",
        "            end = n_images\n",
        "        \n",
        "        batch = images[start:end]\n",
        "        pred = sess.run(inception_layer, {'FID_Inception_Net/ExpandDims:0': batch})\n",
        "        pred_arr[start:end] = pred.reshape(batch.shape[0],-1)\n",
        "    if verbose:\n",
        "        print(\" done\")\n",
        "    return pred_arr\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
        "    \"\"\"Numpy implementation of the Frechet Distance.\n",
        "    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n",
        "    and X_2 ~ N(mu_2, C_2) is\n",
        "            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n",
        "            \n",
        "    Stable version by Dougal J. Sutherland.\n",
        "    Params:\n",
        "    -- mu1 : Numpy array containing the activations of the pool_3 layer of the\n",
        "             inception net ( like returned by the function 'get_predictions')\n",
        "             for generated samples.\n",
        "    -- mu2   : The sample mean over activations of the pool_3 layer, precalcualted\n",
        "               on an representive data set.\n",
        "    -- sigma1: The covariance matrix over activations of the pool_3 layer for\n",
        "               generated samples.\n",
        "    -- sigma2: The covariance matrix over activations of the pool_3 layer,\n",
        "               precalcualted on an representive data set.\n",
        "    Returns:\n",
        "    --   : The Frechet Distance.\n",
        "    \"\"\"\n",
        "\n",
        "    mu1 = np.atleast_1d(mu1)\n",
        "    mu2 = np.atleast_1d(mu2)\n",
        "\n",
        "    sigma1 = np.atleast_2d(sigma1)\n",
        "    sigma2 = np.atleast_2d(sigma2)\n",
        "\n",
        "    assert mu1.shape == mu2.shape, \"Training and test mean vectors have different lengths\"\n",
        "    assert sigma1.shape == sigma2.shape, \"Training and test covariances have different dimensions\"\n",
        "\n",
        "    diff = mu1 - mu2\n",
        "\n",
        "    # product might be almost singular\n",
        "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "    if not np.isfinite(covmean).all():\n",
        "        msg = \"fid calculation produces singular product; adding %s to diagonal of cov estimates\" % eps\n",
        "        warnings.warn(msg)\n",
        "        offset = np.eye(sigma1.shape[0]) * eps\n",
        "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
        "\n",
        "    # numerical error might give slight imaginary component\n",
        "    if np.iscomplexobj(covmean):\n",
        "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
        "            m = np.max(np.abs(covmean.imag))\n",
        "            raise ValueError(\"Imaginary component {}\".format(m))\n",
        "        covmean = covmean.real\n",
        "\n",
        "    tr_covmean = np.trace(covmean)\n",
        "\n",
        "    return diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def calculate_activation_statistics(images, sess, batch_size=50, verbose=False):\n",
        "    \"\"\"Calculation of the statistics used by the FID.\n",
        "    Params:\n",
        "    -- images      : Numpy array of dimension (n_images, hi, wi, 3). The values\n",
        "                     must lie between 0 and 255.\n",
        "    -- sess        : current session\n",
        "    -- batch_size  : the images numpy array is split into batches with batch size\n",
        "                     batch_size. A reasonable batch size depends on the available hardware.\n",
        "    -- verbose     : If set to True and parameter out_step is given, the number of calculated\n",
        "                     batches is reported.\n",
        "    Returns:\n",
        "    -- mu    : The mean over samples of the activations of the pool_3 layer of\n",
        "               the incption model.\n",
        "    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n",
        "               the incption model.\n",
        "    \"\"\"\n",
        "    act = get_activations(images, sess, batch_size, verbose)\n",
        "    mu = np.mean(act, axis=0)\n",
        "    sigma = np.cov(act, rowvar=False)\n",
        "    return mu, sigma\n",
        "    \n",
        "\n",
        "#------------------\n",
        "# The following methods are implemented to obtain a batched version of the activations.\n",
        "# This has the advantage to reduce memory requirements, at the cost of slightly reduced efficiency.\n",
        "# - Pyrestone\n",
        "#------------------\n",
        "\n",
        "\n",
        "def load_image_batch(files):\n",
        "    \"\"\"Convenience method for batch-loading images\n",
        "    Params:\n",
        "    -- files    : list of paths to image files. Images need to have same dimensions for all files.\n",
        "    Returns:\n",
        "    -- A numpy array of dimensions (num_images,hi, wi, 3) representing the image pixel values.\n",
        "    \"\"\"\n",
        "    return np.array([imread(str(fn)).astype(np.float32) for fn in files])\n",
        "\n",
        "def get_activations_from_files(files, sess, batch_size=50, verbose=False):\n",
        "    \"\"\"Calculates the activations of the pool_3 layer for all images.\n",
        "    Params:\n",
        "    -- files      : list of paths to image files. Images need to have same dimensions for all files.\n",
        "    -- sess        : current session\n",
        "    -- batch_size  : the images numpy array is split into batches with batch size\n",
        "                     batch_size. A reasonable batch size depends on the disposable hardware.\n",
        "    -- verbose    : If set to True and parameter out_step is given, the number of calculated\n",
        "                     batches is reported.\n",
        "    Returns:\n",
        "    -- A numpy array of dimension (num images, 2048) that contains the\n",
        "       activations of the given tensor when feeding inception with the query tensor.\n",
        "    \"\"\"\n",
        "    inception_layer = _get_inception_layer(sess)\n",
        "    n_imgs = len(files)\n",
        "    if batch_size > n_imgs:\n",
        "        print(\"warning: batch size is bigger than the data size. setting batch size to data size\")\n",
        "        batch_size = n_imgs\n",
        "    n_batches = n_imgs//batch_size + 1\n",
        "    pred_arr = np.empty((n_imgs,2048))\n",
        "    for i in range(n_batches):\n",
        "        if verbose:\n",
        "            print(\"\\rPropagating batch %d/%d\" % (i+1, n_batches), end=\"\", flush=True)\n",
        "        start = i*batch_size\n",
        "        if start+batch_size < n_imgs:\n",
        "            end = start+batch_size\n",
        "        else:\n",
        "            end = n_imgs\n",
        "        \n",
        "        batch = load_image_batch(files[start:end])\n",
        "        pred = sess.run(inception_layer, {'FID_Inception_Net/ExpandDims:0': batch})\n",
        "        pred_arr[start:end] = pred.reshape(batch_size,-1)\n",
        "        del batch #clean up memory\n",
        "    if verbose:\n",
        "        print(\" done\")\n",
        "    return pred_arr\n",
        "    \n",
        "def calculate_activation_statistics_from_files(files, sess, batch_size=50, verbose=False):\n",
        "    \"\"\"Calculation of the statistics used by the FID.\n",
        "    Params:\n",
        "    -- files      : list of paths to image files. Images need to have same dimensions for all files.\n",
        "    -- sess        : current session\n",
        "    -- batch_size  : the images numpy array is split into batches with batch size\n",
        "                     batch_size. A reasonable batch size depends on the available hardware.\n",
        "    -- verbose     : If set to True and parameter out_step is given, the number of calculated\n",
        "                     batches is reported.\n",
        "    Returns:\n",
        "    -- mu    : The mean over samples of the activations of the pool_3 layer of\n",
        "               the incption model.\n",
        "    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n",
        "               the incption model.\n",
        "    \"\"\"\n",
        "    act = get_activations_from_files(files, sess, batch_size, verbose)\n",
        "    mu = np.mean(act, axis=0)\n",
        "    sigma = np.cov(act, rowvar=False)\n",
        "    return mu, sigma\n",
        "    \n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "# The following functions aren't needed for calculating the FID\n",
        "# they're just here to make this module work as a stand-alone script\n",
        "# for calculating FID scores\n",
        "#-------------------------------------------------------------------------------\n",
        "def check_or_download_inception(inception_path):\n",
        "    ''' Checks if the path to the inception file is valid, or downloads\n",
        "        the file if it is not present. '''\n",
        "    INCEPTION_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
        "    if inception_path is None:\n",
        "        inception_path = '/tmp'\n",
        "    inception_path = pathlib.Path(inception_path)\n",
        "    model_file = inception_path / 'classify_image_graph_def.pb'\n",
        "    if not model_file.exists():\n",
        "        print(\"Downloading Inception model\")\n",
        "        from urllib import request\n",
        "        import tarfile\n",
        "        fn, _ = request.urlretrieve(INCEPTION_URL)\n",
        "        with tarfile.open(fn, mode='r') as f:\n",
        "            f.extract('classify_image_graph_def.pb', str(model_file.parent))\n",
        "    return str(model_file)\n",
        "\n",
        "\n",
        "def _handle_path(path, sess, low_profile=False):\n",
        "    if path.endswith('.npz'):\n",
        "        f = np.load(path)\n",
        "        m, s = f['mu'][:], f['sigma'][:]\n",
        "        f.close()\n",
        "    else:\n",
        "        path = pathlib.Path(path)\n",
        "        files = list(path.glob('*.jpg')) + list(path.glob('*.png'))\n",
        "        if low_profile:\n",
        "            m, s = calculate_activation_statistics_from_files(files, sess)\n",
        "        else:\n",
        "            x = np.array([imread(str(fn)).astype(np.float32) for fn in files])\n",
        "            m, s = calculate_activation_statistics(x, sess)\n",
        "            del x #clean up memory\n",
        "    return m, s\n",
        "\n",
        "\n",
        "def calculate_fid_given_paths(paths, inception_path, low_profile=False):\n",
        "    ''' Calculates the FID of two paths. '''\n",
        "    inception_path = check_or_download_inception(inception_path)\n",
        "\n",
        "    for p in paths:\n",
        "        if not os.path.exists(p):\n",
        "            raise RuntimeError(\"Invalid path: %s\" % p)\n",
        "\n",
        "    create_inception_graph(str(inception_path))\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        m1, s1 = _handle_path(paths[0], sess, low_profile=low_profile)\n",
        "        m2, s2 = _handle_path(paths[1], sess, low_profile=low_profile)\n",
        "        fid_value = calculate_frechet_distance(m1, s1, m2, s2)\n",
        "        return fid_value\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
        "    parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
        "    parser.add_argument(\"path\", type=str, nargs=2,\n",
        "        help='Path to the generated images or to .npz statistic files')\n",
        "    parser.add_argument(\"-i\", \"--inception\", type=str, default=None,\n",
        "        help='Path to Inception model (will be downloaded if not provided)')\n",
        "    parser.add_argument(\"--gpu\", default=\"\", type=str,\n",
        "        help='GPU to use (leave blank for CPU only)')\n",
        "    parser.add_argument(\"--lowprofile\", action=\"store_true\",\n",
        "        help='Keep only one batch of images in memory at a time. This reduces memory footprint, but may decrease speed slightly.')\n",
        "    args = parser.parse_args()\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
        "    fid_value = calculate_fid_given_paths(args.path, args.inception, low_profile=args.lowprofile)\n",
        "    print(\"FID: \", fid_value)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}