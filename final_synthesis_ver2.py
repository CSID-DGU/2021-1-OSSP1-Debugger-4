# -*- coding: utf-8 -*-
"""final_synthesis_ver2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m-xv8aJ3bMwyowIE7Lo7yLHFneURiUnr
"""

from google.colab import drive
drive.mount('./gdrive')

from imutils import face_utils
from google.colab.patches import cv2_imshow
import numpy as np
import imutils
import dlib
import cv2
import math

dx = 0



# 얼굴 Detection 및 Landmark 생성
def faceDetection(img, detector, predictor):
  #h, w, ch = img.shape
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  rects = detector(gray,1)
  roi = rects[0]
  shape = predictor(gray, roi)
  shape = face_utils.shape_to_np(shape)
  #for i in shape:
  #  cv2.circle(img,tuple(i),1,0,2)
  return shape


#마스크부분 추출
def extractMask(landmark, img):
  h, w, ch = img.shape
  # extract jawline
  jawline = landmark[0:17]
  temp_face = landmark[0:17]
  lefteye = landmark[36:42]
  righteye = landmark[42:48]

  nose = landmark[27][1]

  top = nose
  bottom = max(jawline[:,1])
  side1 = min(jawline[:,0])
  side2 = max(jawline[:,0])
  side = side2-side1

  lefteyeline = max(lefteye[:,1])
  righteyeline = max(righteye[:,1])

  # extend contour for masking
  jawline = np.append(jawline, [landmark[47][0],landmark[47][1]]).reshape(-1,2)
  temp_face = np.append(temp_face, [landmark[47][0],landmark[47][1]]).reshape(-1,2)
  jawline = np.append(jawline, [landmark[27][0],landmark[27][1]]).reshape(-1,2)
  temp_face = np.append(temp_face, [landmark[27][0],landmark[27][1]]).reshape(-1,2)
  jawline = np.append(jawline, [ w-1, nose]).reshape(-1,2)
  jawline = np.append(jawline, [ w-1, h-1 ]).reshape(-1, 2)
  jawline = np.append(jawline, [ 0, h-1 ]).reshape(-1, 2)
  jawline = np.append(jawline, [0, nose]).reshape(-1,2)
  jawline = np.append(jawline, [landmark[27][0],landmark[27][1]]).reshape(-1,2)
  jawline = np.append(jawline, [landmark[40][0],landmark[40][1]]).reshape(-1,2)
  temp_face = np.append(temp_face, [landmark[40][0],landmark[40][1]]).reshape(-1,2)
  jawline = np.append(jawline, [landmark[0][0], landmark[0][1] ]).reshape(-1, 2)
  temp_face = np.append(temp_face, [landmark[0][0], landmark[0][1]]).reshape(-1,2)
  contours = [jawline]


  # generate mask
  mask = np.ones((h,w,1), np.uint8) * 255 # times 255 to make mask 'showable'
  
  #print(b,g,r)

  
  cv2.drawContours(mask, contours, -1, 0, -1) # remove below jawline
  

  # apply to image
  result = cv2.bitwise_and(img, img, mask = mask)
  '''
  for i in range(len(temp_face)-1):
    cv2.line(result,(temp_face[i],temp_face[i+1]),(177,206,251),1)
  '''
  b,g,r = img[landmark[27][1],landmark[27][0]]
  #print(b,g,r)
  #bgr = tuple(b,g,r)
  cv2.drawContours(result, [temp_face],-1,(int(b),int(g),int(r)),1)
  result = result[nose:bottom, side1:side2] # crop ROI

  #bluring
  #low_pass_filter_3x3 = np.ones((3, 3), np.float32) / 9.0
  #result = cv2.filter2D(result, -1, low_pass_filter_3x3)


  #sharpening
  #sharpening_2 = np.array([[-1, -1, -1, -1, -1],
  #                       [-1, 2, 2, 2, -1],
  #                       [-1, 2, 9, 2, -1],
  #                       [-1, 2, 2, 2, -1],
  #                       [-1, -1, -1, -1, -1]]) / 9.0
  #result = cv2.filter2D(result, -1, sharpening_2)
  #cv2_imshow(result)
  return result



def coloring(img, img2, landmark_1, landmark_2):
  x1_img1 = int(landmark_1[0][0] + landmark_1[36][0] / 2)
  y1_img1 = landmark_1[36][1]
  x1_img2 = int(landmark_2[0][0] + landmark_2[36][0] / 2)
  y1_img2 = landmark_2[36][1]

  x2_img1 = int((landmark_1[39][0] + landmark_1[27][0]) / 2)
  y2_img1 = landmark_1[27][1]
  x2_img2 = int((landmark_2[39][0] + landmark_2[27][0]) / 2)
  y2_img2 = landmark_2[27][1]

  x3_img1 = int((landmark_1[27][0] + landmark_1[42][0]) / 2)
  y3_img1 = landmark_1[27][1]
  x3_img2 = int((landmark_2[27][0] + landmark_2[42][0]) / 2)
  y3_img2 = landmark_2[27][1]

  x4_img1 = int((landmark_1[45][0] + landmark_1[16][0]) / 2)
  y4_img1 = landmark_1[45][1]
  x4_img2 = int((landmark_2[45][0] + landmark_2[16][0]) / 2)
  y4_img2 = landmark_2[45][1]

  b_1,g_1,r_1 = img[x1_img1][y1_img1]
  b_2,g_2,r_2 = img[x2_img1][y2_img1]
  b_3,g_3,r_3 = img[x3_img1][y3_img1]
  b_4,g_4,r_4 = img[x4_img1][y4_img1]
  b = (b_1+b_2+b_3+b_4)/12
  g = (g_1+g_2+g_3+g_4)/12
  r = (r_1+r_2+r_3+r_4)/12

  b2_1,g2_1,r2_1 = img2[x1_img2][y1_img2]
  b2_2,g2_2,r2_2 = img2[x2_img2][y2_img2]
  b2_3,g2_3,r2_3 = img2[x3_img2][y3_img2]
  b2_4,g2_4,r2_4 = img2[x4_img2][y4_img2]
  b2 = (b2_1+b2_2+b2_3+b2_4)/12
  g2 = (g2_1+g2_2+g2_3+g2_4)/12
  r2 = (r2_1+r2_2+r2_3+r2_4)/12

  blue = int(b-b2)
  green = int(g-g2)
  red = int(r-r2)

  val = min(abs(red), abs(green), abs(blue))
  if(val == -red or val == -blue or val == -green):
    val = val * -1
  
  if(val>0):    
    array = np.full(img2.shape, (val, val, val), dtype = np.uint8)
    img2 = cv2.add(img2, array)
  else:
    array = np.full(img2.shape, (-val, -val, -val), dtype = np.uint8)
    img2 = cv2.subtract(img2, array)
  return img2

def rotate(img,p1,p2,p3,p4):
  #x, y, c = img.shape
  #c = math.sqrt((x1**2)+(y1**2))
  #c2 = math.sqrt((x2**2)+(y2**2))
  w,h = img.shape[:2]

  tan1 = math.atan2(p1[1]-p2[1],p1[0]-p2[0])
  res1 = tan1 * 180 / math.pi

  #tan1 = np.arctan2(*p3[::-1])
  #tan2 = np.arctan2(*p4[::-1])
  #res2 = np.rad2deg((tan1 - tan2) % (2 * np.pi))
  tan2 = math.atan2(p3[1]-p4[1],p3[0]-p4[0])
  res2 = tan2 * 180 / math.pi

  #print(res1)
  #print(res2)
  if(res1<0): #오른쪽으로 돌아간 사진
    handle = "right"
  else:
    handle = "left"
  #cp = (img.shape[1]/2, img.shape[0]/2)
  if(handle == "right"):
    rot = cv2.getRotationMatrix2D((0,0), res2-res1,1)
  else:
    rot = cv2.getRotationMatrix2D((w,0), res2-res1,1)
  img = cv2.warpAffine(img, rot, (0, 0)) 
  return img, handle

    
# 두 이미지 합하기, img_mask : 마스크부분만 자른 이미지, img : 마스크낀 이미지 landmark_1 : 마스크를 낀 사진의 landmark, landmark2 : 마스크를 안낀 사진의 landmark
def func(hpos, vpos, img_mask, img, landmark_1, landmark_2, handle):
  x1 = landmark_1[0][0] - landmark_1[16][0]
  y1 = landmark_1[0][1] - landmark_1[16][1]
  c = math.sqrt((x1**2)+(y1**2))

  x2 = landmark_2[0][0] - landmark_2[16][0]
  y2 = landmark_2[0][1] - landmark_2[16][1]
  c2 = math.sqrt((x2**2)+(y2**2))
  size_w = c/c2

  x3 = landmark_1[27][0] - landmark_1[8][0]
  y3 = landmark_1[27][1] - landmark_1[8][1]
  c3 = math.sqrt((x3**2)+(y3**2))

  x4 = landmark_2[27][0] - landmark_2[8][0]
  y4 = landmark_2[27][1] - landmark_2[8][1]
  c4 = math.sqrt((x4**2)+(y4**2))
  size_h = c3/c4
  
  src = img_mask
  #cv2_imshow(src)
  src = cv2.resize(src, dsize=(0,0), fx =size_w, fy= size_h, interpolation = cv2.INTER_LINEAR)
  rows, cols, channels = src.shape
  if handle=="right":
    roi = img[hpos:rows+hpos,vpos:cols+vpos]
  else:
    roi = img[hpos:rows+hpos,vpos-cols:vpos]
  
  background = np.ones((rows,cols,3), np.uint8)*0
  #cv2_imshow(background)
  gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)
  ret, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY)
  #cv2_imshow(mask)
  mask_inv = cv2.bitwise_not(mask)
  #cv2_imshow(mask_inv)

  src_s = cv2.resize(src, dsize=(0,0), fx = 0.985, fy = 0.985, interpolation = cv2.INTER_LINEAR)
  row2, col2, ch2 = src_s.shape
  y = (int)((rows - row2)/2)
  x = (int)((cols -col2)/2)
  background[y:y+row2, x:x+col2] = src_s
  #cv2_imshow(background)

  gray_s = cv2.cvtColor(background, cv2.COLOR_BGR2GRAY)
  r, mask_s = cv2.threshold(gray_s, 0, 255, cv2.THRESH_BINARY)
  mask_inv = cv2.bitwise_not(mask_s)
  #cv2_imshow(mask_s)

  
  img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)
  #cv2_imshow(img_bg)
  src_fg = cv2.bitwise_and(src, src, mask=mask_s)
  #cv2_imshow(src_fg)
  #src_fg = coloring(src_fg, img_bg)
  tmp = cv2.addWeighted(img_bg, 1, src_fg, 1,0)
  if handle == "right":
    img[hpos:rows+hpos, vpos:cols+vpos] = tmp
  else:
    img[hpos:rows+hpos, vpos-cols:vpos] = tmp

  '''
  img = cv2.line(img, tuple(landmark_1[0]),tuple(landmark_1[40]),(177,206,251),2)
  img = cv2.line(img, tuple(landmark_1[40]),tuple(landmark_1[27]),(177,206,251),2)
  img = cv2.line(img, tuple(landmark_1[27]),tuple(landmark_1[42]),(177,206,251),2)
  img = cv2.line(img, tuple(landmark_1[42]),tuple(landmark_1[16]),(177,206,251),2)
  '''
  return img, tmp

def replace(img, eimg):
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  rects = detector(img, 1)
  for i in rects:
    x1_m = i.left()
    x2_m = i.right()
    y1_m = i.top()
    y2_m = i.bottom()
  h1, w1, ch1 = eimg.shape
  h = ((y2_m-y1_m)/h1)
  w = ((x2_m-x1_m)/w1)
  eimg = cv2.resize(eimg, dsize=(0,0), fx = w, fy = h, interpolation = cv2.INTER_LINEAR)
  img[y1_m:y2_m, x1_m:x2_m] = eimg
  return img

detector = dlib.get_frontal_face_detector()
pred = "./gdrive/MyDrive/opencv/shape_predictor_68_face_landmarks.dat"
predictor = dlib.shape_predictor(pred)

img_path = "./gdrive/MyDrive/opencv/face2.jpg"  #마스크 낀 사진
image = cv2.imread(img_path)
#cv2_imshow(image)

img_path2 = "./gdrive/MyDrive/opencv/face6.jpg"  #마스크 안낀 사진
image2 = cv2.imread(img_path2)

landmark1 = np.empty((68,2),int)
landmark2 = np.empty((68,2),int)

landmark1 = faceDetection(image, detector, predictor)
landmark2 = faceDetection(image2, detector, predictor)

#cv2_imshow(image2)
image2 = coloring(image,image2,landmark1,landmark2)
#cv2_imshow(image2)
show_mask = extractMask(landmark2, image2)
#cv2_imshow(show_mask)
show_mask,r = rotate(show_mask, landmark1[36],landmark1[45],landmark2[36], landmark2[45])
#cv2_imshow(show_mask)
#print(r)

if(r == "right"):
  merged_img, show_mask = func(landmark1[27][1],landmark1[0][0], show_mask, image, landmark1, landmark2, r)
else:
  merged_img, show_mask = func(landmark1[27][1],landmark1[16][0], show_mask, image, landmark1, landmark2, r)
cv2_imshow(merged_img)

img_encoded = cv2.imread("/content/gdrive/MyDrive/opencv/encode.jpg")
merged_img = replace(merged_img, img_encoded)
cv2_imshow(merged_img)
cv2.imwrite("./gdrive/MyDrive/opencv/result.png",merged_img)

result_img = cv2.imread("./gdrive/MyDrive/opencv/result.png")
gray = cv2.cvtColor(result_img, cv2.COLOR_BGR2GRAY)
rects = detector(gray,1)
roi = rects[0]
(x, y, w, h) = face_utils.rect_to_bb(roi)
shape = predictor(gray, roi)
shape = face_utils.shape_to_np(shape)
for i in shape:
  cv2.circle(result_img,tuple(i),1,0,2)
cv2_imshow(result_img)
result_img = result_img[y:y+h,x:x+w]
result_img = cv2.resize(result_img,(800,800))
cv2_imshow(result_img)