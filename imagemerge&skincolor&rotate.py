# -*- coding: utf-8 -*-
"""imageMerge&skinColor&Rotate

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LMGJCyvPDBthwelmAQVut6cX8bqvOVm6
"""

from imutils import face_utils
from google.colab.patches import cv2_imshow
import numpy as np
import imutils
import dlib
import cv2
import math


# 얼굴 Detection 및 Landmark 생성
def faceDetection(img, detector, predictor):
  #h, w, ch = img.shape
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  rects = detector(gray,1)
  roi = rects[0]
  shape = predictor(gray, roi)
  shape = face_utils.shape_to_np(shape)
  return shape


#마스크부분 추출
def extractMask(landmark, img):
  h, w, ch = img.shape
  # extract jawline
  jawline = landmark[0:17]
  lefteye = landmark[36:42]
  righteye = landmark[42:48]

  nose = landmark[27][1]

  top = nose
  bottom = max(jawline[:,1])
  side1 = min(jawline[:,0])
  side2 = max(jawline[:,0])
  side = side2-side1

  lefteyeline = max(lefteye[:,1])
  righteyeline = max(righteye[:,1])

  # extend contour for masking
  jawline = np.append(jawline, [ w-1, landmark[42][1]]).reshape(-1, 2)
  jawline = np.append(jawline, [landmark[47][0],landmark[47][1]]).reshape(-1,2)
  jawline = np.append(jawline, [landmark[27][0],landmark[27][1]]).reshape(-1,2)
  jawline = np.append(jawline, [ w-1, nose]).reshape(-1,2)
  jawline = np.append(jawline, [ w-1, h-1 ]).reshape(-1, 2)
  jawline = np.append(jawline, [ 0, h-1 ]).reshape(-1, 2)
  jawline = np.append(jawline, [0, nose]).reshape(-1,2)
  jawline = np.append(jawline, [landmark[27][0],landmark[27][1]]).reshape(-1,2)
  jawline = np.append(jawline, [landmark[40][0],landmark[40][1]]).reshape(-1,2)
  jawline = np.append(jawline, [ 0, landmark[40][1] ]).reshape(-1, 2)
  contours = [jawline]

  # generate mask
  mask = np.ones((h,w,1), np.uint8) * 255 # times 255 to make mask 'showable'
  cv2.drawContours(mask, contours, -1, 0, -1) # remove below jawline
  # apply to image
  result = cv2.bitwise_and(img, img, mask = mask)
  result = result[nose:bottom, side1:side2] # crop ROI
  return result

# 사람 피부색 영역에 해당하는 마스크를 통해 두 사진에서 얼굴의 색 평균값 추출 이후, 해당 값의 차이만큼 bgr 조정
def coloring(img1, img2):
    img1_ycrcb = cv2.cvtColor(img1, cv2.COLOR_BGR2YCrCb)
    img2_ycrcb = cv2.cvtColor(img2, cv2.COLOR_BGR2YCrCb)
    lower = np.array([0,133,77], dtype = np.unit8)
    upper = np.array([255,173,127], dtype = np.unit8)
    mask1 = cv2.inRange(img1_ycrcb, lower, upper)
    mask2 = cv2.inRange(img2_ycrcb, lower, upper)
    skin1 = cv2.bitwise_and(img1, img1, mask = mask1)
    skin2 = cv2.bitwise_and(img2, img2, mask = mask2)
    
    height1, width1, channel1 = skin1.shape
    tmp = 0
    black = 0
    b1 = 0
    g1 = 0
    r1 = 0
    
    for y in range(0, height1):
        for x in range(0, width1):
            b = skin1.item(y,x,0)
            g = skin1.item(y,x,1)
            r = skin1.item(y,x,2)
            
            if(b==0 and g==0 and r== 0):
                black +=1
            else:
                tmp = +=1
            b1 = b1 + b
            g1 = g1 + g
            r1 = r1 +r
    height2, width2, channel2 = skin1.shape
    tmp2 = 0
    b2 = 0
    g2 = 0
    r2 = 0
    
    for y in range(0, height2):
        for x in range(0, width2):
            b = skin2.item(y,x,0)
            g = skin2.item(y,x,1)
            r = skin2.item(y,x,2)
            
            if(b==0 and g==0 and r== 0):
                black +=1
            else:
                tmp2 = +=1
            b2 = b2 + b
            g2 = g2 + g
            r2 = r2 + r
     
    red = r1/tmp - r2/tmp2
    green = g1/tmp - g2/tmp2
    blue = b1/tmp - b2/tmp2
    
    red2 = red
    green2 = green
    blue2 = blue
    
    if(red<0):
        red2 = red*-1
        red = 0
    if(green<0):
        green2 = green*-1
        green = 0
    if(blue<0):
        blue2 = blue*-1
        blue = 0
    if(red>0)
        red2 = 0
    if(green<0):
        green2 = 0
    if(blue<0):
        blue2 = 0
   
    
    array1 = np.full(img1.shape, (blue, green, red), dtype = np.unit8)
    array2 = np.full(img1.shape, (blue2, green2, red2), dtype = np.unit8)
    img1 = cv2.add(img1, array1)
    img1 = cv2.subtract(img1, array2)
    return img1
  
    
# 두 이미지 합하기, img_mask : 마스크부분만 자른 이미지, img : 마스크낀 이미지 landmark_1 : 마스크를 낀 사진의 landmark, landmark2 : 마스크를 안낀 사진의 landmark
def func(hpos, vpos, img_mask, img, landmark_1, landmark_2):
  x1 = landmark_1[36][0] - landmark_1[45][0]
  y1 = landmark_1[36][1] - landmark_1[45][1]
  c = math.sqrt((x1**2)+(y1**2))

  x2 = landmark_2[36][0] - landmark_2[45][0]
  y2 = landmark_2[36][1] - landmark_2[45][1]
  c2 = math.sqrt((x2**2)+(y2**2))

  size = c/c2

  src = img_mask
  src = cv2.resize(src, dsize=(0,0), fx =size, fy= size, interpolation = cv2.INTER_LINEAR)
  rows, cols, channels = src.shape
  roi = img[hpos:rows+hpos,vpos:cols+vpos]

  gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)
  ret, mask = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)
  mask_inv = cv2.bitwise_not(mask)

  img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)
  src_fg = cv2.bitwise_and(src, src, mask=mask)

  tmp = cv2.add(img_bg, src_fg)
  img[hpos:rows+hpos, vpos:cols+vpos] = tmp
  return img


detector = dlib.get_frontal_face_detector()
pred = "./shape_predictor_68_face_landmarks.dat"
predictor = dlib.shape_predictor(pred)

img_path = "./input_img.jpg"  #마스크 낀 사진
image = cv2.imread(img_path)

img_path2 = "./input_img2.jpg"  #마스크 안낀 사진
image2 = cv2.imread(img_path2)

landmark1 = np.empty((68,2),int)
landmark2 = np.empty((68,2),int)

landmark1 = faceDetection(image, detector, predictor)
landmark2 = faceDetection(image2, detector, predictor)

show_mask = extractMask(landmark2, image2)
new_mask = coloring(show_mask, image)
#cv2_imshow(show_mask)

merged_img = func(landmark1[27][1],landmark1[0][0], new_mask, image, landmark1, landmark2)
cv2_imshow(merged_img)
    
