# -*- coding: utf-8 -*-
"""imageMerge&skinColor&Rotate

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LMGJCyvPDBthwelmAQVut6cX8bqvOVm6
"""

from imutils import face_utils
from google.colab.patches import cv2_imshow
import numpy as np
import imutils
import dlib
import cv2
import math

dx = 0
# 얼굴 Detection 및 Landmark 생성
def faceDetection(img, detector, predictor):
  #h, w, ch = img.shape
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  rects = detector(gray,1)
  roi = rects[0]
  shape = predictor(gray, roi)
  shape = face_utils.shape_to_np(shape)
  return shape


#마스크부분 추출
def extractMask(landmark, img):
  h, w, ch = img.shape
  # extract jawline
  jawline = landmark[0:17]
  lefteye = landmark[36:42]
  righteye = landmark[42:48]

  nose = landmark[27][1]

  top = nose
  bottom = max(jawline[:,1])
  side1 = min(jawline[:,0])
  side2 = max(jawline[:,0])
  side = side2-side1

  lefteyeline = max(lefteye[:,1])
  righteyeline = max(righteye[:,1])

  # extend contour for masking
  jawline = np.append(jawline, [ w-1, landmark[42][1]]).reshape(-1, 2)
  jawline = np.append(jawline, [landmark[47][0],landmark[47][1]]).reshape(-1,2)
  jawline = np.append(jawline, [landmark[27][0],landmark[27][1]]).reshape(-1,2)
  jawline = np.append(jawline, [ w-1, nose]).reshape(-1,2)
  jawline = np.append(jawline, [ w-1, h-1 ]).reshape(-1, 2)
  jawline = np.append(jawline, [ 0, h-1 ]).reshape(-1, 2)
  jawline = np.append(jawline, [0, nose]).reshape(-1,2)
  jawline = np.append(jawline, [landmark[27][0],landmark[27][1]]).reshape(-1,2)
  jawline = np.append(jawline, [landmark[40][0],landmark[40][1]]).reshape(-1,2)
  jawline = np.append(jawline, [ 0, landmark[40][1] ]).reshape(-1, 2)
  contours = [jawline]

  # generate mask
  mask = np.ones((h,w,1), np.uint8) * 255 # times 255 to make mask 'showable'
  cv2.drawContours(mask, contours, -1, 0, -1) # remove below jawline
  # apply to image
  result = cv2.bitwise_and(img, img, mask = mask)
  result = result[nose:bottom, side1:side2] # crop ROI
  return result

# 사람 피부색 영역에 해당하는 마스크를 통해 두 사진에서 얼굴의 색 평균값 추출 이후, 해당 값의 차이만큼 bgr 조정
def coloring(img1, img2):
    img1_ycrcb = cv2.cvtColor(img1, cv2.COLOR_BGR2YCrCb)
    img2_ycrcb = cv2.cvtColor(img2, cv2.COLOR_BGR2YCrCb)
    lower = np.array([0,133,77], dtype = np.uint8)
    upper = np.array([255,173,127], dtype = np.uint8)
    mask1 = cv2.inRange(img1_ycrcb, lower, upper)
    mask2 = cv2.inRange(img2_ycrcb, lower, upper)
    skin1 = cv2.bitwise_and(img1, img1, mask = mask1)
    skin2 = cv2.bitwise_and(img2, img2, mask = mask2)
    cv2_imshow(skin1)
    cv2_imshow(skin2)
    height1, width1, channel1 = skin1.shape
    tmp = 0
    black = 0
    b1 = 0
    g1 = 0
    r1 = 0
    
    for y in range(0, height1):
        for x in range(0, width1):
            b = skin1.item(y,x,0)
            g = skin1.item(y,x,1)
            r = skin1.item(y,x,2)
            
            if(b==0 and g==0 and r== 0):
                black +=1
            else:
                tmp +=1
            b1 = b1 + b
            g1 = g1 + g
            r1 = r1 +r

    height2, width2, channel2 = skin2.shape
    tmp2 = 0
    b2 = 0
    g2 = 0
    r2 = 0
    
    for y in range(0, height2):
        for x in range(0, width2):
            b = skin2.item(y,x,0)
            g = skin2.item(y,x,1)
            r = skin2.item(y,x,2)
            
            if(b==0 or g==0 or r== 0):
                black +=1
            else:
                tmp2  +=1
            b2 = b2 + b
            g2 = g2 + g
            r2 = r2 + r
     
    red =  r2/tmp2 -r1/tmp
    green = g2/tmp2 - g1/tmp
    blue = b2/tmp2 - b1/tmp
   
    val = min(abs(red), abs(green), abs(blue))
    if(val == -red or val == -blue or val == -green):
        val = val * -1

    if(val>0):    
      array = np.full(img1.shape, (val, val, val), dtype = np.uint8)
      img1 = cv2.add(img1, array)
    else:
      array = np.full(img1.shape, (-val, -val, -val), dtype = np.uint8)
      img1 = cv2.subtract(img1, array)
    return img1

#def rotate(img,x1,y1,x2,y2):
#  x, y, c = img.shape
#  c = math.sqrt((x1**2)+(y1**2))
#  c2 = math.sqrt((x2**2)+(y2**2))

#  if(c2>c):
#   d = c2-c
#    tan1 = np.arctan2(d, c2)
#    angle = np.rad2deg(tan1) * -1/2
#  else :
#    d = c-c2
#    tan1 = np.arctan2(d, c) 
#    angle = np.rad2deg(tan1)/2
#  if(angle>0):
#    dx = int(d/4)
#  else:
#    dx = int(-d/4)
#  print(dx)
#  cp = (img.shape[1]/2, img.shape[0]/2)
#  rot = cv2.getRotationMatrix2D(cp, angle,1)
#  img = cv2.warpAffine(img, rot, (0, 0)) 
#  cv2_imshow(img)
#  return img
    
# 두 이미지 합하기, img_mask : 마스크부분만 자른 이미지, img : 마스크낀 이미지 landmark_1 : 마스크를 낀 사진의 landmark, landmark2 : 마스크를 안낀 사진의 landmark
def func(hpos, vpos, img_mask, img, landmark_1, landmark_2):
  x1 = landmark_1[36][0] - landmark_1[45][0]
  y1 = landmark_1[36][1] - landmark_1[45][1]
  c = math.sqrt((x1**2)+(y1**2))

  x2 = landmark_2[36][0] - landmark_2[45][0]
  y2 = landmark_2[36][1] - landmark_2[45][1]
  c2 = math.sqrt((x2**2)+(y2**2))
  print(c2, c)
  print(dx)
  size = c2/c

  src = img_mask
  src = cv2.resize(src, dsize=(0,0), fx =size, fy= size, interpolation = cv2.INTER_LINEAR)
  rows, cols, channels = src.shape
  roi = img[hpos:rows+hpos,vpos-8:cols+vpos-8]

  gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)
  ret, mask = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)
  mask_inv = cv2.bitwise_not(mask)

  img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)
  src_fg = cv2.bitwise_and(src, src, mask=mask)
  src_fg = coloring(src_fg, img_bg)

  tmp = cv2.add(img_bg, src_fg)
  img[hpos:rows+hpos, vpos:cols+vpos] = tmp
  return img


detector = dlib.get_frontal_face_detector()
pred = "/gdrive/MyDrive/shape_predictor_68_face_landmarks.dat"
predictor = dlib.shape_predictor(pred)

img_path = "/gdrive/MyDrive/face1.jpg"  #마스크 낀 사진
image = cv2.imread(img_path)

img_path2 = "/gdrive/MyDrive/face2.jpg"  #마스크 안낀 사진
image2 = cv2.imread(img_path2)

landmark1 = np.empty((68,2),int)
landmark2 = np.empty((68,2),int)

landmark1 = faceDetection(image, detector, predictor)
landmark2 = faceDetection(image2, detector, predictor)

show_mask = extractMask(landmark1, image)
cv2_imshow(show_mask)
#show_mask = rotate(show_mask, landmark1[36][0] - landmark1[45][0],landmark1[36][1] - landmark1[45][1], landmark2[36][0] - landmark2[45][0], landmark2[36][1] - landmark2[45][1])
cv2_imshow(show_mask)

merged_img = func(landmark2[27][1],landmark2[0][0], show_mask, image2, landmark1, landmark2)
cv2_imshow(merged_img)
    
