# -*- coding: utf-8 -*-
"""imageMerge&skinColor&Rotate

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LMGJCyvPDBthwelmAQVut6cX8bqvOVm6
"""

from imutils import face_utils
from google.colab.patches import cv2_imshow
import numpy as np
import imutils
import dlib
import cv2
import math


# 얼굴 Detection 및 Landmark 생성
def faceDetection(img, detector, predictor):
  #h, w, ch = img.shape
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  rects = detector(gray,1)
  roi = rects[0]
  shape = predictor(gray, roi)
  shape = face_utils.shape_to_np(shape)
  return shape


#마스크부분 추출
def extractMask(landmark, img):
  h, w, ch = img.shape
  # extract jawline
  jawline = landmark[0:17]
  lefteye = landmark[36:42]
  righteye = landmark[42:48]

  nose = landmark[27][1]

  top = nose
  bottom = max(jawline[:,1])
  side1 = min(jawline[:,0])
  side2 = max(jawline[:,0])
  side = side2-side1

  lefteyeline = max(lefteye[:,1])
  righteyeline = max(righteye[:,1])

  # extend contour for masking
  jawline = np.append(jawline, [ w-1, landmark[42][1]]).reshape(-1, 2)
  jawline = np.append(jawline, [landmark[47][0],landmark[47][1]]).reshape(-1,2)
  jawline = np.append(jawline, [landmark[27][0],landmark[27][1]]).reshape(-1,2)
  jawline = np.append(jawline, [ w-1, nose]).reshape(-1,2)
  jawline = np.append(jawline, [ w-1, h-1 ]).reshape(-1, 2)
  jawline = np.append(jawline, [ 0, h-1 ]).reshape(-1, 2)
  jawline = np.append(jawline, [0, nose]).reshape(-1,2)
  jawline = np.append(jawline, [landmark[27][0],landmark[27][1]]).reshape(-1,2)
  jawline = np.append(jawline, [landmark[40][0],landmark[40][1]]).reshape(-1,2)
  jawline = np.append(jawline, [ 0, landmark[40][1] ]).reshape(-1, 2)
  contours = [jawline]

  # generate mask
  mask = np.ones((h,w,1), np.uint8) * 255 # times 255 to make mask 'showable'
  cv2.drawContours(mask, contours, -1, 0, -1) # remove below jawline
  # apply to image
  result = cv2.bitwise_and(img, img, mask = mask)
  result = result[nose:bottom, side1:side2] # crop ROI
  return result



# 두 이미지 합하기, img_mask : 마스크부분만 자른 이미지, img : 마스크낀 이미지 landmark_1 : 마스크를 낀 사진의 landmark, landmark2 : 마스크를 안낀 사진의 landmark
def func(hpos, vpos, img_mask, img, landmark_1, landmark_2):
  x1 = landmark_1[36][0] - landmark_1[45][0]
  y1 = landmark_1[36][1] - landmark_1[45][1]
  c = math.sqrt((x1**2)+(y1**2))

  x2 = landmark_2[36][0] - landmark_2[45][0]
  y2 = landmark_2[36][1] - landmark_2[45][1]
  c2 = math.sqrt((x2**2)+(y2**2))

  size = c/c2

  src = img_mask
  src = cv2.resize(src, dsize=(0,0), fx =size, fy= size, interpolation = cv2.INTER_LINEAR)
  rows, cols, channels = src.shape
  roi = img[hpos:rows+hpos,vpos:cols+vpos]

  gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)
  ret, mask = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)
  mask_inv = cv2.bitwise_not(mask)

  img_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)
  src_fg = cv2.bitwise_and(src, src, mask=mask)

  tmp = cv2.add(img_bg, src_fg)
  img[hpos:rows+hpos, vpos:cols+vpos] = tmp
  return img


detector = dlib.get_frontal_face_detector()
pred = "./shape_predictor_68_face_landmarks.dat"
predictor = dlib.shape_predictor(pred)

img_path = "./input_img.jpg"  #마스크 낀 사진
image = cv2.imread(img_path)

img_path2 = "./input_img2.jpg"  #마스크 안낀 사진
image2 = cv2.imread(img_path2)

landmark1 = np.empty((68,2),int)
landmark2 = np.empty((68,2),int)

landmark1 = faceDetection(image, detector, predictor)
landmark2 = faceDetection(image2, detector, predictor)

show_mask = extractMask(landmark2, image2)
#cv2_imshow(show_mask)

merged_img = func(landmark1[27][1],landmark1[0][0], show_mask, image, landmark1, landmark2)
cv2_imshow(merged_img)